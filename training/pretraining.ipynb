{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"roberta_small_bulgarian_pretraining_with_trainer.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bd1080bbcede40c381e0e1c7ac676a0d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dfd7f4bb1b644639b20c41abaf543900","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e16b6c7843ed433e8b6b2252276e3596","IPY_MODEL_8084214cb2a44535b53e33883d231881"]}},"dfd7f4bb1b644639b20c41abaf543900":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e16b6c7843ed433e8b6b2252276e3596":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6acca08140d04bdbb1a3ecba497082fa","_dom_classes":[],"description":"Epoch:   0%","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e5bf7308d1649f081308a3fb97a4f51"}},"8084214cb2a44535b53e33883d231881":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ff666fb7704a4b07ae4b2a5a38330357","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/1 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4de05df23fdd48339ac3c43cd20c1aa5"}},"6acca08140d04bdbb1a3ecba497082fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7e5bf7308d1649f081308a3fb97a4f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ff666fb7704a4b07ae4b2a5a38330357":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4de05df23fdd48339ac3c43cd20c1aa5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f12a75088d02428aaf5b6adcb7467365":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0a59bd933fd14de8abdfec84072c376a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3534517a49704d309198bb322fe15a99","IPY_MODEL_5b37cb02a1dd44448d1bbf51e988c0e3"]}},"0a59bd933fd14de8abdfec84072c376a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3534517a49704d309198bb322fe15a99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_73b53bf254214e18ba10c929f961c3fe","_dom_classes":[],"description":"Iteration:  52%","_model_name":"FloatProgressModel","bar_style":"","max":168709,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":163117,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af0219f876da452db87fd428b4cd567c"}},"5b37cb02a1dd44448d1bbf51e988c0e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1354ea332cf8454aab5f612a1e4ebd3a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 163117/168709 [11:14:11&lt;35:44,  2.61it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7217ee5bff8d4ca3bf890716a2aa7648"}},"73b53bf254214e18ba10c929f961c3fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"af0219f876da452db87fd428b4cd567c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1354ea332cf8454aab5f612a1e4ebd3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7217ee5bff8d4ca3bf890716a2aa7648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26f4de7a67bf44a5a2e4756e87c4b179":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0425af1f92e145e4add00fea7656d690","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_67d55c4fabc4422695a5c8b8f7d45f01","IPY_MODEL_274b186cede5488199e1935919ad00bb"]}},"0425af1f92e145e4add00fea7656d690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67d55c4fabc4422695a5c8b8f7d45f01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_84efae680c4f41179b00c49709f4de52","_dom_classes":[],"description":"Epoch: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_45168fe835514234ab88b3dfec3a0583"}},"274b186cede5488199e1935919ad00bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0bf033b7fb354707a55c912dbc7a7c15","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [1:30:31&lt;00:00, 5431.31s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e0e0a67332e45f986a17af64bce10b8"}},"84efae680c4f41179b00c49709f4de52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"45168fe835514234ab88b3dfec3a0583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0bf033b7fb354707a55c912dbc7a7c15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8e0e0a67332e45f986a17af64bce10b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a5b8d736d5548efa85181eeee50d1d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1ce22d024a714f1eb744129c760e3470","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e94bb5de92dd454d952efac631f5562a","IPY_MODEL_3d9f6e62e977461d9036bbb25d51bee5"]}},"1ce22d024a714f1eb744129c760e3470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e94bb5de92dd454d952efac631f5562a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7a0ca6ac1d7840f2a35f473eff56ce2f","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":168709,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":168709,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_edc57fd9b040473c8fc313ad53f0c770"}},"3d9f6e62e977461d9036bbb25d51bee5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab584b4cd78e4696b6ba3f9d9cb9fae5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 168709/168709 [1:30:31&lt;00:00, 31.06it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b3efbbb84a0d4545890e4c521fc993d4"}},"7a0ca6ac1d7840f2a35f473eff56ce2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"edc57fd9b040473c8fc313ad53f0c770":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab584b4cd78e4696b6ba3f9d9cb9fae5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b3efbbb84a0d4545890e4c521fc993d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"GwiEucYFqPTx","colab_type":"text"},"source":["# Pretraining RoBERTa for Bulgarian Masked-Language-Modeling\n","\n","The notebook is based on [this guide](https://huggingface.co/blog/how-to-train)."]},{"cell_type":"code","metadata":{"id":"eg3S9GbisouU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"status":"ok","timestamp":1598052209449,"user_tz":-540,"elapsed":10546,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"4587c25a-cf00-4fe7-ea7f-badf926f8b38"},"source":["!pip install transformers==2.11.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers==2.11.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n","\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2.23.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 16.0MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 19.0MB/s \n","\u001b[?25hCollecting tokenizers==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 28.1MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2019.12.20)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (20.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (1.18.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b4ff218183e35a53b783a14dbcdba57691a0913de0d642a27ad225c193e5d886\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jaJ08iymgunz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598052213041,"user_tz":-540,"elapsed":13502,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"ce023791-9b66-461f-d16e-a6967f751413"},"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hy92IUpvhKum","colab_type":"text"},"source":["# Training the tokenizer"]},{"cell_type":"code","metadata":{"id":"2LKiYJfSykHR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598052266020,"user_tz":-540,"elapsed":1628,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"3597f36e-6b4c-4594-b032-3b868ddc6198"},"source":["%cd '/content/drive/My Drive/ml_hw/NLP/bulgarian/'\n","\n","from tokenizers import ByteLevelBPETokenizer\n","\n","datapaths= ['bul_wikipedia_2016_1M-sentences_notab.txt',\n","            'bul_newscrawl_2017_1M-sentences_notab.txt']\n","\n","tokenizer = ByteLevelBPETokenizer()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/ml_hw/NLP/bulgarian\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9CK_d54aXQFW","colab_type":"code","colab":{}},"source":["MODEL_DIR = \"./roberta-small-bg\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IL3V_tPETbP3","colab_type":"code","colab":{}},"source":["tokenizer.train(files=datapaths, vocab_size=52_000, min_frequency=2, show_progress=True, special_tokens=[\n","    \"<s>\",\n","    \"<pad>\",\n","    \"</s>\",\n","    \"<unk>\",\n","    \"<mask>\"\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTZYaBaWPXhZ","colab_type":"code","colab":{}},"source":["!mkdir roberta-small-bg\n","tokenizer.save(MODEL_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTYzWGzXhE9Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597921664129,"user_tz":-540,"elapsed":73519,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"028f5dca-9cdb-40fa-b0b6-8731601757de"},"source":["from tokenizers.implementations import ByteLevelBPETokenizer\n","from tokenizers.processors import BertProcessing\n","\n","tokenizer = ByteLevelBPETokenizer(\n","    MODEL_DIR + \"/vocab.json\",\n","    MODEL_DIR + \"/merges.txt\",\n",")\n","tokenizer._tokenizer.post_processor = BertProcessing(\n","    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n","    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",")\n","tokenizer.enable_truncation(max_length=512)\n","\n","print(tokenizer.encode(\"аз съм мъж\").ids)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0, 964, 1081, 2115, 2]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yNzb0XokhP4u","colab_type":"text"},"source":["# Pretraining the model"]},{"cell_type":"code","metadata":{"id":"yeuAcOxWjFCG","colab_type":"code","colab":{}},"source":["from transformers import RobertaTokenizerFast\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_DIR, model_max_length=512)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VtYUQaGqhTRW","colab_type":"text"},"source":["## Dataset preprocessing"]},{"cell_type":"code","metadata":{"id":"n_4q48cJDv9B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":605},"executionInfo":{"status":"ok","timestamp":1598055932315,"user_tz":-540,"elapsed":3653666,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"303402fd-3df1-47c8-deb5-ecf32bd99bfb"},"source":["from torch.utils.data import Dataset\n","import transformers\n","\n","MAX_SEQ_LEN = 512\n","\n","class TextDataset(Dataset):\n","\n","    def __init__(self, tokenizer: transformers.PreTrainedTokenizer, file_paths):\n","        lines = []\n","        i = 1\n","        for path in file_paths:\n","            print('Reading {}/{} {}'.format(i, len(file_paths), path))\n","            with open(path, encoding=\"utf-8\") as f:\n","                lines.extend(\n","                    [line for line in f.read().splitlines() if (len(line) > 0 and not line.isspace())]\n","                )\n","            i += 1\n","        print('Packing sequences...')\n","        packed_sequences = self.pack_sequences(lines)\n","        self.examples = packed_sequences\n","        print('Dataset ready.')\n","    \n","    def pack_sequences(self, text):\n","        data = []\n","\n","        concat_len = 0\n","        concat_string = \"\"\n","\n","        i = 0\n","        checkpoints = [i for i in range(10, 110, 10)]\n","        \n","        for line in text:\n","\n","            percent = round((i / len(text)) * 100)\n","            if percent in checkpoints:\n","                print('{}% complete'.format(percent))\n","                checkpoints.pop(0)\n","\n","            # first tokenize the current line\n","            encoding = tokenizer.encode_plus(\n","                line,\n","                truncation=True\n","            )\n","            tokenized_line = encoding['input_ids']\n","\n","            # then we'll try to add it to the current sequence we're packing\n","            if concat_len + len(tokenized_line) < MAX_SEQ_LEN:\n","                concat_len += len(tokenized_line)\n","                concat_string += line\n","\n","            # if the current sequence is already full, add it and make a new one    \n","            else:\n","                data.append(concat_string)\n","                concat_len = len(tokenized_line)\n","                concat_string = line\n","            \n","            i += 1\n","\n","        # we'll have one unfinished sequence left over after iterating\n","        data.append(concat_string)\n","\n","        return data\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, i) -> torch.Tensor:\n","        encoding = tokenizer.encode_plus(\n","            self.examples[i], \n","            add_special_tokens=True, \n","            truncation=True,\n","            max_length=MAX_SEQ_LEN)\n","        return torch.tensor(encoding['input_ids'], dtype=torch.long)\n","\n","datapaths = ['bul_newscrawl_2017_1M-sentences_notab.txt', \n","             'bul_wikipedia_2016_1M-sentences_notab.txt']\n","datapaths.extend(\n","    ['bg_text_{}.txt'.format(i) for i in range(1_000_000, 9_000_000, 1_000_000)]\n",")\n","\n","train_dataset = TextDataset(tokenizer, datapaths)\n","eval_dataset = TextDataset(tokenizer, ['bg_text_26000000.txt'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading 1/10 bul_newscrawl_2017_1M-sentences_notab.txt\n","Reading 2/10 bul_wikipedia_2016_1M-sentences_notab.txt\n","Reading 3/10 bg_text_1000000.txt\n","Reading 4/10 bg_text_2000000.txt\n","Reading 5/10 bg_text_3000000.txt\n","Reading 6/10 bg_text_4000000.txt\n","Reading 7/10 bg_text_5000000.txt\n","Reading 8/10 bg_text_6000000.txt\n","Reading 9/10 bg_text_7000000.txt\n","Reading 10/10 bg_text_8000000.txt\n","Packing sequences...\n","10% complete\n","20% complete\n","30% complete\n","40% complete\n","50% complete\n","60% complete\n","70% complete\n","80% complete\n","90% complete\n","100% complete\n","Dataset ready.\n","Reading 1/1 bg_text_26000000.txt\n","Packing sequences...\n","10% complete\n","20% complete\n","30% complete\n","40% complete\n","50% complete\n","60% complete\n","70% complete\n","80% complete\n","90% complete\n","100% complete\n","Dataset ready.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v995D-jIhY6G","colab_type":"text"},"source":["## Model Configuration"]},{"cell_type":"code","metadata":{"id":"BvccXZcf9EZc","colab_type":"code","colab":{}},"source":["from transformers import RobertaForMaskedLM\n","from transformers import RobertaConfig\n","\n","config = RobertaConfig(\n","    vocab_size=52_000,\n","    max_position_embeddings=514,\n","    num_attention_heads=12,\n","    num_hidden_layers=6,\n","    type_vocab_size=1,\n",")\n","\n","model = RobertaForMaskedLM(config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o7EwFP2ThjhF","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"7mz3fZTAKMCk","colab_type":"code","colab":{}},"source":["from transformers import Trainer, TrainingArguments\n","from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",")\n","\n","training_args = TrainingArguments(\n","    output_dir=MODEL_DIR,\n","    overwrite_output_dir=True,\n","    num_train_epochs=1,\n","    per_device_train_batch_size=8,\n","    logging_steps=1_000,\n","    save_steps=20000\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    prediction_loss_only=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUCR1kSiKlg9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["4b4deea3af454e1abd3444bc0982cd7d","0dbd28b113104d2192aab9d8beffed39"]},"outputId":"90cd1e84-729c-4df3-c3d1-70be1a32062c"},"source":["trainer.train()\n","trainer.save_model(MODEL_DIR)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b4deea3af454e1abd3444bc0982cd7d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0dbd28b113104d2192aab9d8beffed39","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=168709.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{\"loss\": 7.940483513355255, \"learning_rate\": 4.970363169718272e-05, \"epoch\": 0.005927366056345542, \"step\": 1000}\n","{\"loss\": 7.51009136724472, \"learning_rate\": 4.940726339436545e-05, \"epoch\": 0.011854732112691084, \"step\": 2000}\n","{\"loss\": 7.38911885356903, \"learning_rate\": 4.911089509154817e-05, \"epoch\": 0.017782098169036625, \"step\": 3000}\n","{\"loss\": 7.304487721443176, \"learning_rate\": 4.88145267887309e-05, \"epoch\": 0.023709464225382167, \"step\": 4000}\n","{\"loss\": 7.253735353946686, \"learning_rate\": 4.8518158485913614e-05, \"epoch\": 0.02963683028172771, \"step\": 5000}\n","{\"loss\": 7.201186093330383, \"learning_rate\": 4.8221790183096335e-05, \"epoch\": 0.03556419633807325, \"step\": 6000}\n","{\"loss\": 7.176096982955933, \"learning_rate\": 4.792542188027906e-05, \"epoch\": 0.04149156239441879, \"step\": 7000}\n","{\"loss\": 7.1339053525924685, \"learning_rate\": 4.7629053577461784e-05, \"epoch\": 0.047418928450764335, \"step\": 8000}\n","{\"loss\": 7.118884016990662, \"learning_rate\": 4.7332685274644505e-05, \"epoch\": 0.05334629450710988, \"step\": 9000}\n","{\"loss\": 7.077240037918091, \"learning_rate\": 4.703631697182723e-05, \"epoch\": 0.05927366056345542, \"step\": 10000}\n","{\"loss\": 7.054204169273376, \"learning_rate\": 4.673994866900995e-05, \"epoch\": 0.06520102661980096, \"step\": 11000}\n","{\"loss\": 7.017373915195465, \"learning_rate\": 4.644358036619268e-05, \"epoch\": 0.0711283926761465, \"step\": 12000}\n","{\"loss\": 6.993808363437653, \"learning_rate\": 4.61472120633754e-05, \"epoch\": 0.07705575873249204, \"step\": 13000}\n","{\"loss\": 6.96039727640152, \"learning_rate\": 4.585084376055812e-05, \"epoch\": 0.08298312478883758, \"step\": 14000}\n","{\"loss\": 6.9389879446029665, \"learning_rate\": 4.5554475457740844e-05, \"epoch\": 0.08891049084518313, \"step\": 15000}\n","{\"loss\": 6.912977408409119, \"learning_rate\": 4.5258107154923565e-05, \"epoch\": 0.09483785690152867, \"step\": 16000}\n","{\"loss\": 6.897042898654938, \"learning_rate\": 4.496173885210629e-05, \"epoch\": 0.10076522295787421, \"step\": 17000}\n","{\"loss\": 6.863088769435882, \"learning_rate\": 4.4665370549289014e-05, \"epoch\": 0.10669258901421975, \"step\": 18000}\n","{\"loss\": 6.848880782604217, \"learning_rate\": 4.4369002246471734e-05, \"epoch\": 0.1126199550705653, \"step\": 19000}\n","{\"loss\": 6.815159171581269, \"learning_rate\": 4.407263394365446e-05, \"epoch\": 0.11854732112691084, \"step\": 20000}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["{\"loss\": 6.792776386737824, \"learning_rate\": 4.377626564083718e-05, \"epoch\": 0.12447468718325638, \"step\": 21000}\n","{\"loss\": 6.782762974262238, \"learning_rate\": 4.3479897338019904e-05, \"epoch\": 0.1304020532396019, \"step\": 22000}\n","{\"loss\": 6.743408578395844, \"learning_rate\": 4.318352903520263e-05, \"epoch\": 0.13632941929594747, \"step\": 23000}\n","{\"loss\": 6.686858028411865, \"learning_rate\": 4.288716073238535e-05, \"epoch\": 0.142256785352293, \"step\": 24000}\n","{\"loss\": 6.60186936712265, \"learning_rate\": 4.2590792429568074e-05, \"epoch\": 0.14818415140863855, \"step\": 25000}\n","{\"loss\": 6.503564147949219, \"learning_rate\": 4.2294424126750795e-05, \"epoch\": 0.15411151746498408, \"step\": 26000}\n","{\"loss\": 6.417073035240174, \"learning_rate\": 4.1998055823933516e-05, \"epoch\": 0.16003888352132964, \"step\": 27000}\n","{\"loss\": 6.301224122524261, \"learning_rate\": 4.1701687521116243e-05, \"epoch\": 0.16596624957767517, \"step\": 28000}\n","{\"loss\": 6.214125962257385, \"learning_rate\": 4.1405319218298964e-05, \"epoch\": 0.1718936156340207, \"step\": 29000}\n","{\"loss\": 6.126258303165436, \"learning_rate\": 4.110895091548169e-05, \"epoch\": 0.17782098169036625, \"step\": 30000}\n","{\"loss\": 6.046043941497802, \"learning_rate\": 4.081258261266441e-05, \"epoch\": 0.18374834774671178, \"step\": 31000}\n","{\"loss\": 5.957177381038666, \"learning_rate\": 4.0516214309847134e-05, \"epoch\": 0.18967571380305734, \"step\": 32000}\n","{\"loss\": 5.882796823501587, \"learning_rate\": 4.021984600702986e-05, \"epoch\": 0.19560307985940287, \"step\": 33000}\n","{\"loss\": 5.786377319335937, \"learning_rate\": 3.992347770421258e-05, \"epoch\": 0.20153044591574842, \"step\": 34000}\n","Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UZXq_OOiW8s1","colab_type":"text"},"source":["The training stopped at some point so let's reload from a checkpoint"]},{"cell_type":"code","metadata":{"id":"0UssZBF0WvkY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":114,"referenced_widgets":["bd1080bbcede40c381e0e1c7ac676a0d","dfd7f4bb1b644639b20c41abaf543900","e16b6c7843ed433e8b6b2252276e3596","8084214cb2a44535b53e33883d231881","6acca08140d04bdbb1a3ecba497082fa","7e5bf7308d1649f081308a3fb97a4f51","ff666fb7704a4b07ae4b2a5a38330357","4de05df23fdd48339ac3c43cd20c1aa5","f12a75088d02428aaf5b6adcb7467365","0a59bd933fd14de8abdfec84072c376a","3534517a49704d309198bb322fe15a99","5b37cb02a1dd44448d1bbf51e988c0e3","73b53bf254214e18ba10c929f961c3fe","af0219f876da452db87fd428b4cd567c","1354ea332cf8454aab5f612a1e4ebd3a","7217ee5bff8d4ca3bf890716a2aa7648"]},"outputId":"3a4d18b3-7496-40bf-9af8-08fe61f95795"},"source":["model = RobertaForMaskedLM(config=config).from_pretrained(MODEL_DIR + '/checkpoint-60000')\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    prediction_loss_only=True,\n",")\n","\n","trainer.train(MODEL_DIR + '/checkpoint-60000')\n","trainer.save_model(MODEL_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd1080bbcede40c381e0e1c7ac676a0d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f12a75088d02428aaf5b6adcb7467365","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=168709.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{\"loss\": 3.925383972167969, \"learning_rate\": 3.1921533528146096e-05, \"epoch\": 0.36156932943707804, \"step\": 61000}\n","{\"loss\": 3.8892468149662016, \"learning_rate\": 3.1625165225328824e-05, \"epoch\": 0.36749669549342356, \"step\": 62000}\n","{\"loss\": 3.861357157945633, \"learning_rate\": 3.1328796922511545e-05, \"epoch\": 0.37342406154976915, \"step\": 63000}\n","{\"loss\": 3.8234396750926973, \"learning_rate\": 3.103242861969427e-05, \"epoch\": 0.3793514276061147, \"step\": 64000}\n","{\"loss\": 3.8271664266586303, \"learning_rate\": 3.073606031687699e-05, \"epoch\": 0.3852787936624602, \"step\": 65000}\n","{\"loss\": 3.782004462480545, \"learning_rate\": 3.043969201405971e-05, \"epoch\": 0.39120615971880573, \"step\": 66000}\n","{\"loss\": 3.7677099952697755, \"learning_rate\": 3.014332371124244e-05, \"epoch\": 0.3971335257751513, \"step\": 67000}\n","{\"loss\": 3.7563066110610963, \"learning_rate\": 2.984695540842516e-05, \"epoch\": 0.40306089183149685, \"step\": 68000}\n","{\"loss\": 3.7345009541511534, \"learning_rate\": 2.955058710560788e-05, \"epoch\": 0.4089882578878424, \"step\": 69000}\n","{\"loss\": 3.7100100376605987, \"learning_rate\": 2.9254218802790605e-05, \"epoch\": 0.4149156239441879, \"step\": 70000}\n","{\"loss\": 3.696688935995102, \"learning_rate\": 2.8957850499973326e-05, \"epoch\": 0.4208429900005335, \"step\": 71000}\n","{\"loss\": 3.6773738934993743, \"learning_rate\": 2.8661482197156054e-05, \"epoch\": 0.426770356056879, \"step\": 72000}\n","{\"loss\": 3.65033180975914, \"learning_rate\": 2.8365113894338775e-05, \"epoch\": 0.43269772211322455, \"step\": 73000}\n","{\"loss\": 3.637146013259888, \"learning_rate\": 2.8068745591521496e-05, \"epoch\": 0.4386250881695701, \"step\": 74000}\n","{\"loss\": 3.6071971282958986, \"learning_rate\": 2.777237728870422e-05, \"epoch\": 0.4445524542259156, \"step\": 75000}\n","{\"loss\": 3.593625697851181, \"learning_rate\": 2.747600898588694e-05, \"epoch\": 0.4504798202822612, \"step\": 76000}\n","{\"loss\": 3.5891049320697785, \"learning_rate\": 2.717964068306967e-05, \"epoch\": 0.4564071863386067, \"step\": 77000}\n","{\"loss\": 3.5673270394802095, \"learning_rate\": 2.688327238025239e-05, \"epoch\": 0.46233455239495225, \"step\": 78000}\n","{\"loss\": 3.559048669576645, \"learning_rate\": 2.658690407743511e-05, \"epoch\": 0.4682619184512978, \"step\": 79000}\n","{\"loss\": 3.5445055088996886, \"learning_rate\": 2.6290535774617835e-05, \"epoch\": 0.47418928450764336, \"step\": 80000}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["{\"loss\": 3.5365067932605743, \"learning_rate\": 2.5994167471800556e-05, \"epoch\": 0.4801166505639889, \"step\": 81000}\n","{\"loss\": 3.51975986289978, \"learning_rate\": 2.5697799168983277e-05, \"epoch\": 0.4860440166203344, \"step\": 82000}\n","{\"loss\": 3.513608780860901, \"learning_rate\": 2.5401430866166004e-05, \"epoch\": 0.49197138267667995, \"step\": 83000}\n","{\"loss\": 3.4903784427642823, \"learning_rate\": 2.5105062563348725e-05, \"epoch\": 0.49789874873302553, \"step\": 84000}\n","{\"loss\": 3.494800758123398, \"learning_rate\": 2.480869426053145e-05, \"epoch\": 0.503826114789371, \"step\": 85000}\n","{\"loss\": 3.4653803877830507, \"learning_rate\": 2.451232595771417e-05, \"epoch\": 0.5097534808457166, \"step\": 86000}\n","{\"loss\": 3.460529038906097, \"learning_rate\": 2.4215957654896895e-05, \"epoch\": 0.5156808469020622, \"step\": 87000}\n","Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3cuITPn0cxYf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282,"referenced_widgets":["26f4de7a67bf44a5a2e4756e87c4b179","0425af1f92e145e4add00fea7656d690","67d55c4fabc4422695a5c8b8f7d45f01","274b186cede5488199e1935919ad00bb","84efae680c4f41179b00c49709f4de52","45168fe835514234ab88b3dfec3a0583","0bf033b7fb354707a55c912dbc7a7c15","8e0e0a67332e45f986a17af64bce10b8","9a5b8d736d5548efa85181eeee50d1d3","1ce22d024a714f1eb744129c760e3470","e94bb5de92dd454d952efac631f5562a","3d9f6e62e977461d9036bbb25d51bee5","7a0ca6ac1d7840f2a35f473eff56ce2f","edc57fd9b040473c8fc313ad53f0c770","ab584b4cd78e4696b6ba3f9d9cb9fae5","b3efbbb84a0d4545890e4c521fc993d4"]},"executionInfo":{"status":"ok","timestamp":1598061508962,"user_tz":-540,"elapsed":5558533,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"5c4bc25f-99fd-4007-ecd1-93076bc65f49"},"source":["model = RobertaForMaskedLM(config=config).from_pretrained(MODEL_DIR + '/checkpoint-160000')\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    prediction_loss_only=True,\n",")\n","\n","trainer.train(MODEL_DIR + '/checkpoint-160000')\n","trainer.save_model(MODEL_DIR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:218: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n","  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26f4de7a67bf44a5a2e4756e87c4b179","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a5b8d736d5548efa85181eeee50d1d3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=168709.0, style=ProgressStyle(description…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["{\"loss\": 3.0524137647151948, \"learning_rate\": 2.284703246418389e-06, \"epoch\": 0.9543059350716322, \"step\": 161000}\n","{\"loss\": 3.0630431191921232, \"learning_rate\": 1.988334943601112e-06, \"epoch\": 0.9602333011279778, \"step\": 162000}\n","{\"loss\": 3.055609819173813, \"learning_rate\": 1.6919666407838351e-06, \"epoch\": 0.9661606671843233, \"step\": 163000}\n","{\"loss\": 3.054229326248169, \"learning_rate\": 1.395598337966558e-06, \"epoch\": 0.9720880332406688, \"step\": 164000}\n","{\"loss\": 3.0462097029685973, \"learning_rate\": 1.0992300351492807e-06, \"epoch\": 0.9780153992970144, \"step\": 165000}\n","{\"loss\": 3.051473555088043, \"learning_rate\": 8.028617323320036e-07, \"epoch\": 0.9839427653533599, \"step\": 166000}\n","{\"loss\": 3.05576734995842, \"learning_rate\": 5.064934295147266e-07, \"epoch\": 0.9898701314097055, \"step\": 167000}\n","{\"loss\": 3.0550967285633086, \"learning_rate\": 2.101251266974495e-07, \"epoch\": 0.9957974974660511, \"step\": 168000}\n","\n","\n"],"name":"stdout"}]}]}
