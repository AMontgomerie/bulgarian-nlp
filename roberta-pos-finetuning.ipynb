{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"roberta-pos-finetuning.ipynb","provenance":[{"file_id":"115Mau1UtJYwBy4pQE1gc7pDKKt5pSqa5","timestamp":1597815268420}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1eoqlzlUYvioJ83FNYtLLVc-hKTQgW-eW","authorship_tag":"ABX9TyMdnVtM3hpynHtODGebGuUt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ycFGBghBvKM0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"status":"ok","timestamp":1597917147129,"user_tz":-540,"elapsed":7479,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"7c5af6bd-e77e-4acf-ce9e-beef5ffe0fd9"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 15.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 20.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 59.3MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=8291d75bbe60b189998ae972417019fe0dcf60a09e51843f20684000198aebe7\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pAXE0a50vQr7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1597917150335,"user_tz":-540,"elapsed":10672,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"f2fdc649-8b67-47c6-e85c-59d41fce6696"},"source":["!pip install conllu"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting conllu\n","  Downloading https://files.pythonhosted.org/packages/8e/49/eb3c57e95839d89d50cd667af29694543774fee480a52879ef8c689e5d9d/conllu-4.0-py2.py3-none-any.whl\n","Installing collected packages: conllu\n","Successfully installed conllu-4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xChhM68f3hdy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597917154054,"user_tz":-540,"elapsed":14380,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"cc75a631-d6e1-4715-cde4-b08a251a0612"},"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ALCMxDcXvV7t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1597917198694,"user_tz":-540,"elapsed":59012,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"78f53159-f472-4149-c923-651b6df48573"},"source":["%cd '/content/drive/My Drive/ml_hw/NLP/bulgarian/'\n","\n","MODEL = \"./roberta-base-bg\"\n","\n","from transformers import RobertaTokenizerFast\n","from torch.utils.data import Dataset, DataLoader\n","from conllu import parse_incr\n","import numpy as np\n","import string\n","import re\n","\n","BATCH_SIZE = 16\n","MAX_LEN = 128\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(MODEL, max_len=MAX_LEN)\n","\n","tag_to_id = {'ADJ': 0, 'ADP': 1, 'PUNCT': 2, 'ADV': 3, 'AUX': 4, 'SYM': 5, \n","              'INTJ': 6, 'CCONJ': 7, 'X': 8, 'NOUN': 9, 'DET': 10, 'PROPN': 11, \n","              'NUM': 12, 'VERB': 13, 'PART': 14, 'PRON': 15, 'SCONJ': 16}\n","\n","id_to_tag = {tag_to_id[tag]: tag for tag in tag_to_id}\n","\n","class POSDataset(Dataset):\n","\n","    def __init__(self, data_path):\n","        self.data = []\n","\n","        data_file = open(data_path, 'r', encoding=\"utf8\")\n","\n","        failed_count = 0\n","        for token_list in parse_incr(data_file):\n","\n","            # first we need to tokenize the text\n","            text = token_list.metadata['text'] \n","            text = self.preprocess_punctuation(text)\n","            tokenized_text = tokenizer(\n","                text, \n","                max_length=MAX_LEN,\n","                padding='max_length',\n","                truncation=True,\n","                add_special_tokens=True,\n","                return_offsets_mapping=True,\n","                return_tensors='pt'\n","            )\n","\n","            # next we can get the pos tags and encode them\n","            tags = [token['upos'] for token in token_list]\n","            encoded_labels = self.encode_tags(tags, tokenized_text.offset_mapping)\n","            if encoded_labels:\n","                self.data.append({\n","                    'input_ids': torch.squeeze(tokenized_text['input_ids']),\n","                    'attention_mask': torch.squeeze(tokenized_text['attention_mask']),\n","                    'labels': torch.tensor(encoded_labels)})\n","            else:\n","                failed_count += 1\n","        print(\"Unable to process {} examples\".format(failed_count))\n","    \n","    def encode_tags(self, pos_tags, offset_mapping):\n","        labels = [tag_to_id[tag] for tag in pos_tags]\n","        encoded_labels = np.ones(len(offset_mapping), dtype=int) * -100\n","\n","        for i in range(1, len(offset_mapping)):\n","            if self.ignore_mapping(offset_mapping[i-1]) or offset_mapping[i-1][-1] != offset_mapping[i][0]:\n","                if not self.ignore_mapping(offset_mapping[i]):\n","                    try:\n","                        encoded_labels[i] = labels.pop(0)\n","                    except(IndexError):\n","                        return None\n","        \n","        if len(labels) > 0:\n","            return None\n","\n","        return encoded_labels.tolist()\n","\n","    def ignore_mapping(self, mapping):\n","        return mapping[0] == mapping[1]\n","\n","    def preprocess_punctuation(self, text):\n","        text = text.replace('...', '.')\n","        text = text.replace('..', '.')\n","        text = re.sub('([,.:;?!\\()\"\"''])', r' \\1 ', text)\n","        text = re.sub('\\s{2,}', ' ', text)\n","        return text\n","\n","    def __getitem__(self, index):\n","        item = self.data[index]\n","        item['input_ids'] = item['input_ids'].to(device)\n","        item['attention_mask'] = item['attention_mask'].to(device)\n","        item['labels'] = item['labels'].to(device)\n","        return item\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","pos_paths = ['conllu/bg_btb-ud-dev.conllu',\n","             'conllu/bg_btb-ud-test.conllu',\n","             'conllu/bg_btb-ud-train.conllu']\n","\n","dev_set, test_set, train_set = [POSDataset(path) for path in pos_paths]\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\n","dev_loader = DataLoader(dev_set, batch_size=BATCH_SIZE)\n","test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/ml_hw/NLP/bulgarian\n","Unable to process 89 examples\n","Unable to process 79 examples\n","Unable to process 722 examples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZQHF1wKt28-f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597918279509,"user_tz":-540,"elapsed":5160,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"6a3b204f-83cf-4c1b-a739-63ec6e081c17"},"source":["from transformers import RobertaForTokenClassification\n","\n","learning_rate = 1e-4\n","\n","model = RobertaForTokenClassification.from_pretrained(\n","    MODEL, \n","    num_labels=len(tag_to_id)\n",")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","model.to(device)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at ./roberta-base-bg were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at ./roberta-base-bg and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"jtQupMHX-REH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597918279510,"user_tz":-540,"elapsed":1347,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["LOG_INTERVAL = round(len(train_loader) / 10)\n","\n","def train(epoch):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch_index, batch in enumerate(train_loader):\n","        model.zero_grad()\n","        output = model(**batch)\n","        loss = output[0]\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if batch_index % LOG_INTERVAL == 0 and batch_index > 0:\n","            current_loss = total_loss / LOG_INTERVAL\n","            print('| epoch {:3d} | ' \n","                  '{:5d}/{:5d} batches | '\n","                  'loss {:5.2f}'.format(\n","                    epoch, \n","                    batch_index, len(train_loader), \n","                    current_loss))\n","            total_loss = 0\n","\n","def test(data_loader):\n","    model.eval()\n","    total_score = 0\n","    total_len = 0\n","\n","    with torch.no_grad():\n","        for batch_index, batch in enumerate(data_loader):\n","            output = model(**batch)\n","            preds = np.argmax(output[1].cpu(), axis=2)\n","            preds = preds[(batch['labels'] != -100)]\n","            labels = batch['labels'][(batch['labels'] != -100)]\n","            total_score += preds.eq(labels.cpu()).sum()\n","            total_len += len(labels)\n","    return (total_score.item() / total_len) * 100"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2kCUruUAdAq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597918579746,"user_tz":-540,"elapsed":298293,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"cf929577-1b51-49fc-dc45-855cb8f136f5"},"source":["EPOCHS = 5\n","\n","accuracy = test(dev_loader)\n","print('| Pretraining Accuracy: {:.2f}%\\n'.format(accuracy))\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train(epoch)\n","    accuracy = test(dev_loader)\n","    print('| epoch   {} |  Accuracy: {:.2f}%\\n'.format(epoch, accuracy))\n","\n","accuracy = test(test_loader)\n","print('\\n Final Accuracy: {}%'.format(accuracy))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["| Pretraining Accuracy: 8.67%\n","\n","| epoch   1 |    51/  512 batches | loss  0.71\n","| epoch   1 |   102/  512 batches | loss  0.20\n","| epoch   1 |   153/  512 batches | loss  0.13\n","| epoch   1 |   204/  512 batches | loss  0.16\n","| epoch   1 |   255/  512 batches | loss  0.14\n","| epoch   1 |   306/  512 batches | loss  0.11\n","| epoch   1 |   357/  512 batches | loss  0.11\n","| epoch   1 |   408/  512 batches | loss  0.11\n","| epoch   1 |   459/  512 batches | loss  0.11\n","| epoch   1 |   510/  512 batches | loss  0.09\n","| epoch   1 |  Accuracy: 97.70%\n","\n","| epoch   2 |    51/  512 batches | loss  0.13\n","| epoch   2 |   102/  512 batches | loss  0.07\n","| epoch   2 |   153/  512 batches | loss  0.06\n","| epoch   2 |   204/  512 batches | loss  0.07\n","| epoch   2 |   255/  512 batches | loss  0.06\n","| epoch   2 |   306/  512 batches | loss  0.04\n","| epoch   2 |   357/  512 batches | loss  0.05\n","| epoch   2 |   408/  512 batches | loss  0.04\n","| epoch   2 |   459/  512 batches | loss  0.05\n","| epoch   2 |   510/  512 batches | loss  0.04\n","| epoch   2 |  Accuracy: 97.79%\n","\n","| epoch   3 |    51/  512 batches | loss  0.08\n","| epoch   3 |   102/  512 batches | loss  0.04\n","| epoch   3 |   153/  512 batches | loss  0.03\n","| epoch   3 |   204/  512 batches | loss  0.04\n","| epoch   3 |   255/  512 batches | loss  0.03\n","| epoch   3 |   306/  512 batches | loss  0.03\n","| epoch   3 |   357/  512 batches | loss  0.03\n","| epoch   3 |   408/  512 batches | loss  0.03\n","| epoch   3 |   459/  512 batches | loss  0.03\n","| epoch   3 |   510/  512 batches | loss  0.03\n","| epoch   3 |  Accuracy: 97.55%\n","\n","| epoch   4 |    51/  512 batches | loss  0.06\n","| epoch   4 |   102/  512 batches | loss  0.04\n","| epoch   4 |   153/  512 batches | loss  0.03\n","| epoch   4 |   204/  512 batches | loss  0.03\n","| epoch   4 |   255/  512 batches | loss  0.04\n","| epoch   4 |   306/  512 batches | loss  0.03\n","| epoch   4 |   357/  512 batches | loss  0.02\n","| epoch   4 |   408/  512 batches | loss  0.02\n","| epoch   4 |   459/  512 batches | loss  0.03\n","| epoch   4 |   510/  512 batches | loss  0.02\n","| epoch   4 |  Accuracy: 97.93%\n","\n","| epoch   5 |    51/  512 batches | loss  0.03\n","| epoch   5 |   102/  512 batches | loss  0.03\n","| epoch   5 |   153/  512 batches | loss  0.02\n","| epoch   5 |   204/  512 batches | loss  0.02\n","| epoch   5 |   255/  512 batches | loss  0.03\n","| epoch   5 |   306/  512 batches | loss  0.01\n","| epoch   5 |   357/  512 batches | loss  0.02\n","| epoch   5 |   408/  512 batches | loss  0.02\n","| epoch   5 |   459/  512 batches | loss  0.02\n","| epoch   5 |   510/  512 batches | loss  0.02\n","| epoch   5 |  Accuracy: 97.82%\n","\n","\n"," Final Accuracy: 97.74894810659187%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bk96n_xEOfaz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597919260035,"user_tz":-540,"elapsed":1663,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["torch.save(model.state_dict(), 'roberta-base-bg-pos.pt')"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"j24ADMnRYi_p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1597920099413,"user_tz":-540,"elapsed":484,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"53b60e27-6ea6-4c09-aee3-7f219fd2f41a"},"source":["def get_relevant_labels(offset_mapping):\n","    relevant_labels = np.zeros(len(offset_mapping), dtype=int)\n","\n","    for i in range(1, len(offset_mapping)):\n","        if ignore_mapping(offset_mapping[i-1]) or offset_mapping[i-1][-1] != offset_mapping[i][0]:\n","            if not ignore_mapping(offset_mapping[i]):\n","                relevant_labels[i] = 1\n","\n","    return relevant_labels\n","\n","def ignore_mapping(mapping):\n","    return mapping[0] == mapping[1]\n","\n","with torch.no_grad():\n","    model.eval()\n","    input = 'Аз сьм мьж.'\n","    tokenized_text = tokenizer(\n","        input, \n","        max_length=MAX_LEN,\n","        padding='max_length',\n","        truncation=True,\n","        add_special_tokens=True,\n","        return_offsets_mapping=True,\n","        return_tensors='pt'\n","    )\n","    tokenized_text['input_ids'] = tokenized_text['input_ids'].to(device)\n","    tokenized_text['attention_mask'] = tokenized_text['attention_mask'].to(device)\n","    output = model(\n","        input_ids=tokenized_text['input_ids'], \n","        attention_mask=tokenized_text['attention_mask']\n","    )\n","    preds = np.argmax(output[0].cpu(), axis=2)\n","    relevant = get_relevant_labels(tokenized_text['offset_mapping'])\n","    predicted_labels = preds[0][relevant == True].tolist()\n","    print(\"Input sentence: {}\".format(input))\n","    print(\"Predictions: {}\".format([id_to_tag[id] for id in predicted_labels]))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Input sentence: Аз сьм мьж.\n","Predictions: ['PRON', 'VERB', 'NOUN']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x79YkLMRiTYB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1597921827875,"user_tz":-540,"elapsed":1833,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"1cd18252-8489-4b5c-da42-9b819986b267"},"source":["path = './roberta-base-bulgarian-pos'\n","model.save_pretrained(path)\n","tokenizer.save_pretrained(path)"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('./roberta-base-bulgarian-pos/vocab.json',\n"," './roberta-base-bulgarian-pos/merges.txt',\n"," './roberta-base-bulgarian-pos/special_tokens_map.json',\n"," './roberta-base-bulgarian-pos/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":34}]}]}