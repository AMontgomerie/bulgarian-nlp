{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"roberta-pos-finetuning-last-token.ipynb","provenance":[{"file_id":"1eoqlzlUYvioJ83FNYtLLVc-hKTQgW-eW","timestamp":1597970891966},{"file_id":"115Mau1UtJYwBy4pQE1gc7pDKKt5pSqa5","timestamp":1597815268420}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1C4THC0zgmgk3L7rfxjIwPx1aaQ8gdkws","authorship_tag":"ABX9TyNvJgbqyaYjxN1iTpKwFzNA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bb970ea892dc4d0b97ecfa628cf20ac8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ed416689207740899262a0636120125f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_07811418e7354b33b8b3513d472ddf5c","IPY_MODEL_968b05da48774650b1362c5a4d025adc"]}},"ed416689207740899262a0636120125f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07811418e7354b33b8b3513d472ddf5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8944d97615a94f7d92856bc03aae7dcb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1790545,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1790545,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae4ada6802a84d19a0377847ec6073ae"}},"968b05da48774650b1362c5a4d025adc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7edb9bff210040d8a2b91aaa4245582e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.79M/1.79M [00:03&lt;00:00, 580kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_014745a66df1451797e1e6a8b3d1b3bc"}},"8944d97615a94f7d92856bc03aae7dcb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ae4ada6802a84d19a0377847ec6073ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7edb9bff210040d8a2b91aaa4245582e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"014745a66df1451797e1e6a8b3d1b3bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e744078f4c44dfd8448b95513f4c858":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c27e7d3434384dff912379e5482a0e76","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7030a1bbcfa944b8998d6517155609ab","IPY_MODEL_8d9572766b6440258324e452d37055e8"]}},"c27e7d3434384dff912379e5482a0e76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7030a1bbcfa944b8998d6517155609ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_48566a663bc54102b2f9113ee0cd5c14","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1436710,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1436710,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3500ad5d9a174a2081a86715afddebb3"}},"8d9572766b6440258324e452d37055e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cdf156246ef3438e9a5c92de1e363a23","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.44M/1.44M [00:01&lt;00:00, 831kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd5a2973b1784f189673acd4851bc35b"}},"48566a663bc54102b2f9113ee0cd5c14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3500ad5d9a174a2081a86715afddebb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cdf156246ef3438e9a5c92de1e363a23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fd5a2973b1784f189673acd4851bc35b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"922d302f2d3449348bb2a2f75077f749":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f3396865b6ce473988a40f2c6a3479d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5ca4ea185fe44dfc93a6d5ac29664e49","IPY_MODEL_98e6f3a833d64ef4b333a0a24a8fed75"]}},"f3396865b6ce473988a40f2c6a3479d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ca4ea185fe44dfc93a6d5ac29664e49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3e4b75117d8d48a9bd3ee1c95455f790","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":239,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":239,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4757a1043d3843ea93581098b9e45e9a"}},"98e6f3a833d64ef4b333a0a24a8fed75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c555b4986504f47b22e4e6adfd00fdc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 239/239 [00:02&lt;00:00, 85.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f12d3bdfde174b868df2ac71201b6c36"}},"3e4b75117d8d48a9bd3ee1c95455f790":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4757a1043d3843ea93581098b9e45e9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c555b4986504f47b22e4e6adfd00fdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f12d3bdfde174b868df2ac71201b6c36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08a59aa2f4484ed0800fb9491801b0d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3d8d7f5340734e1d9b700ce49a0e2291","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4a050111c4b3445ab8727428c6dc8c1d","IPY_MODEL_aab9f2fe32da44b790eb0fc038291c28"]}},"3d8d7f5340734e1d9b700ce49a0e2291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a050111c4b3445ab8727428c6dc8c1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5cf9a01deb61481a9b9ea57f6e92002f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":78,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":78,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_441f24a0bc7a46c3ad80a1fef512f601"}},"aab9f2fe32da44b790eb0fc038291c28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1ab58dc4e0ae4081835d2f83319c548e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 78.0/78.0 [00:01&lt;00:00, 46.8B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1186d9146024c3d9943c1b7e2f82ed0"}},"5cf9a01deb61481a9b9ea57f6e92002f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"441f24a0bc7a46c3ad80a1fef512f601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ab58dc4e0ae4081835d2f83319c548e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e1186d9146024c3d9943c1b7e2f82ed0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"pQQJtP7nfSH2","colab_type":"text"},"source":["# Fine-Tuning *RoBERTa-small-bulgarian* For Part-Of-Speech Tagging."]},{"cell_type":"code","metadata":{"id":"ycFGBghBvKM0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600134758270,"user_tz":-540,"elapsed":9633,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["%%capture\n","\n","!pip install transformers==3.0.2\n","!pip install conllu"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"xChhM68f3hdy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600134761879,"user_tz":-540,"elapsed":13232,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"75060acd-91bf-484f-c438-0d8a7c704085"},"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-WCmY-lcflxN","colab_type":"text"},"source":["## Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"ALCMxDcXvV7t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":279,"referenced_widgets":["bb970ea892dc4d0b97ecfa628cf20ac8","ed416689207740899262a0636120125f","07811418e7354b33b8b3513d472ddf5c","968b05da48774650b1362c5a4d025adc","8944d97615a94f7d92856bc03aae7dcb","ae4ada6802a84d19a0377847ec6073ae","7edb9bff210040d8a2b91aaa4245582e","014745a66df1451797e1e6a8b3d1b3bc","8e744078f4c44dfd8448b95513f4c858","c27e7d3434384dff912379e5482a0e76","7030a1bbcfa944b8998d6517155609ab","8d9572766b6440258324e452d37055e8","48566a663bc54102b2f9113ee0cd5c14","3500ad5d9a174a2081a86715afddebb3","cdf156246ef3438e9a5c92de1e363a23","fd5a2973b1784f189673acd4851bc35b","922d302f2d3449348bb2a2f75077f749","f3396865b6ce473988a40f2c6a3479d2","5ca4ea185fe44dfc93a6d5ac29664e49","98e6f3a833d64ef4b333a0a24a8fed75","3e4b75117d8d48a9bd3ee1c95455f790","4757a1043d3843ea93581098b9e45e9a","8c555b4986504f47b22e4e6adfd00fdc","f12d3bdfde174b868df2ac71201b6c36","08a59aa2f4484ed0800fb9491801b0d0","3d8d7f5340734e1d9b700ce49a0e2291","4a050111c4b3445ab8727428c6dc8c1d","aab9f2fe32da44b790eb0fc038291c28","5cf9a01deb61481a9b9ea57f6e92002f","441f24a0bc7a46c3ad80a1fef512f601","1ab58dc4e0ae4081835d2f83319c548e","e1186d9146024c3d9943c1b7e2f82ed0"]},"executionInfo":{"status":"ok","timestamp":1600134800201,"user_tz":-540,"elapsed":51545,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"c74f0283-5d47-41be-ecdf-90e124127e19"},"source":["%cd '/content/drive/My Drive/ml_hw/NLP/bulgarian/'\n","\n","MODEL = \"iarfmoose/roberta-small-bulgarian\"\n","\n","from transformers import RobertaTokenizerFast\n","from torch.utils.data import Dataset, DataLoader\n","from conllu import parse_incr\n","import numpy as np\n","import string\n","import re\n","\n","BATCH_SIZE = 16\n","MAX_LEN = 128\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(MODEL, max_len=MAX_LEN)\n","\n","tag_to_id = {'ADJ': 0, 'ADP': 1, 'PUNCT': 2, 'ADV': 3, 'AUX': 4, 'SYM': 5, \n","              'INTJ': 6, 'CCONJ': 7, 'X': 8, 'NOUN': 9, 'DET': 10, 'PROPN': 11, \n","              'NUM': 12, 'VERB': 13, 'PART': 14, 'PRON': 15, 'SCONJ': 16}\n","\n","id_to_tag = {tag_to_id[tag]: tag for tag in tag_to_id}\n","\n","class POSDataset(Dataset):\n","\n","    def __init__(self, data_path):\n","        self.data = []\n","\n","        data_file = open(data_path, 'r', encoding=\"utf8\")\n","\n","        failed_count = 0\n","        for token_list in parse_incr(data_file):\n","\n","            # first we need to tokenize the text\n","            text = token_list.metadata['text'] \n","            text = self.preprocess_punctuation(text)\n","            tokenized_text = tokenizer(\n","                text, \n","                max_length=MAX_LEN,\n","                padding='max_length',\n","                truncation=True,\n","                add_special_tokens=True,\n","                return_offsets_mapping=True,\n","                return_tensors='pt'\n","            )\n","\n","            # next we can get the pos tags and encode them\n","            tags = [token['upos'] for token in token_list]\n","            encoded_labels = self.encode_tags_last(tags, tokenized_text.offset_mapping)\n","            if encoded_labels:\n","                self.data.append({\n","                    'input_ids': torch.squeeze(tokenized_text['input_ids']),\n","                    'attention_mask': torch.squeeze(tokenized_text['attention_mask']),\n","                    'labels': torch.tensor(encoded_labels)})\n","            else:\n","                failed_count += 1\n","        print(\"Unable to process {} examples\".format(failed_count))\n","\n","    # encodes labels in the first token position of each word\n","    def encode_tags_first(self, pos_tags, offset_mapping):\n","        labels = [tag_to_id[tag] for tag in pos_tags]\n","        encoded_labels = np.ones(len(offset_mapping), dtype=int) * -100\n","\n","        for i in range(1, len(offset_mapping)):\n","            if self.ignore_mapping(offset_mapping[i-1]) or offset_mapping[i-1][-1] != offset_mapping[i][0]:\n","                if not self.ignore_mapping(offset_mapping[i]):\n","                    try:\n","                        encoded_labels[i] = labels.pop(0)\n","                    except(IndexError):\n","                        return None\n","        \n","        if len(labels) > 0:\n","            return None\n","\n","        return encoded_labels.tolist()\n","\n","    # encodes labels in the last token position of each word\n","    def encode_tags_last(self, pos_tags, offset_mapping):\n","        labels = [tag_to_id[tag] for tag in pos_tags]\n","        encoded_labels = np.ones(len(offset_mapping), dtype=int) * -100\n","\n","        for i in range(1, len(offset_mapping) - 1):\n","            \n","            if offset_mapping[i][1] != offset_mapping[i+1][0]:\n","                if not self.ignore_mapping(offset_mapping[i]):\n","                    try:\n","                        encoded_labels[i] = labels.pop(0)\n","                    except(IndexError):\n","                        return None\n","        \n","        if len(labels) > 0:\n","            return None\n","\n","        return encoded_labels.tolist()\n","\n","    def ignore_mapping(self, mapping):\n","        return mapping[0] == mapping[1]\n","\n","    def preprocess_punctuation(self, text):\n","        text = text.replace('...', '.')\n","        text = text.replace('..', '.')\n","        text = re.sub('([,.:;?!\\()\"\"''])', r' \\1 ', text)\n","        text = re.sub('\\s{2,}', ' ', text)\n","        return text\n","\n","    def __getitem__(self, index):\n","        item = self.data[index]\n","        item['input_ids'] = item['input_ids'].to(device)\n","        item['attention_mask'] = item['attention_mask'].to(device)\n","        item['labels'] = item['labels'].to(device)\n","        return item\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","pos_paths = ['conllu/bg_btb-ud-dev.conllu',\n","             'conllu/bg_btb-ud-test.conllu',\n","             'conllu/bg_btb-ud-train.conllu']\n","\n","dev_set, test_set, train_set = [POSDataset(path) for path in pos_paths]\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\n","dev_loader = DataLoader(dev_set, batch_size=BATCH_SIZE)\n","test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/ml_hw/NLP/bulgarian\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb970ea892dc4d0b97ecfa628cf20ac8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1790545.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e744078f4c44dfd8448b95513f4c858","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1436710.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"922d302f2d3449348bb2a2f75077f749","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=239.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08a59aa2f4484ed0800fb9491801b0d0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=78.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Unable to process 89 examples\n","Unable to process 79 examples\n","Unable to process 722 examples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ybkxMrWIfrPF","colab_type":"text"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"ZQHF1wKt28-f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600135047969,"user_tz":-540,"elapsed":5380,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"9c7231e7-6ce5-4d3f-b26c-204c18a9f599"},"source":["from transformers import RobertaForTokenClassification\n","\n","learning_rate = 1e-4\n","\n","model = RobertaForTokenClassification.from_pretrained(\n","    MODEL, \n","    num_labels=len(tag_to_id)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","model.to(device)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at iarfmoose/roberta-small-bulgarian were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at iarfmoose/roberta-small-bulgarian and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RobertaForTokenClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"OG7tNo18furN","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"jtQupMHX-REH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600134830503,"user_tz":-540,"elapsed":81833,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["LOG_INTERVAL = round(len(train_loader) / 10)\n","\n","def train(epoch):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch_index, batch in enumerate(train_loader):\n","        model.zero_grad()\n","        output = model(**batch)\n","        loss = output[0]\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        if batch_index % LOG_INTERVAL == 0 and batch_index > 0:\n","            current_loss = total_loss / LOG_INTERVAL\n","            print('| epoch {:3d} | ' \n","                  '{:5d}/{:5d} batches | '\n","                  'loss {:5.2f}'.format(\n","                    epoch, \n","                    batch_index, len(train_loader), \n","                    current_loss))\n","            total_loss = 0\n","\n","def test(data_loader):\n","    model.eval()\n","    total_score = 0\n","    total_len = 0\n","\n","    with torch.no_grad():\n","        for batch_index, batch in enumerate(data_loader):\n","            output = model(**batch)\n","            preds = np.argmax(output[1].cpu(), axis=2)\n","            preds = preds[(batch['labels'] != -100)]\n","            labels = batch['labels'][(batch['labels'] != -100)]\n","            total_score += preds.eq(labels.cpu()).sum()\n","            total_len += len(labels)\n","    return (total_score.item() / total_len) * 100"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2kCUruUAdAq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600135230081,"user_tz":-540,"elapsed":181696,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"f3d3d5c9-60cc-4358-9540-40d04ac5a67a"},"source":["EPOCHS = 5\n","\n","accuracy = test(dev_loader)\n","print('| Pretraining Accuracy: {:.2f}%\\n'.format(accuracy))\n","\n","for epoch in range(1, EPOCHS + 1):\n","    train(epoch)\n","    accuracy = test(dev_loader)\n","    print('| epoch   {} |  Accuracy: {:.2f}%\\n'.format(epoch, accuracy))\n","\n","accuracy = test(test_loader)\n","print('\\n Final Accuracy: {}%'.format(accuracy))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["| Pretraining Accuracy: 5.34%\n","\n","| epoch   1 |    51/  512 batches | loss  0.63\n","| epoch   1 |   102/  512 batches | loss  0.16\n","| epoch   1 |   153/  512 batches | loss  0.10\n","| epoch   1 |   204/  512 batches | loss  0.14\n","| epoch   1 |   255/  512 batches | loss  0.13\n","| epoch   1 |   306/  512 batches | loss  0.09\n","| epoch   1 |   357/  512 batches | loss  0.09\n","| epoch   1 |   408/  512 batches | loss  0.09\n","| epoch   1 |   459/  512 batches | loss  0.09\n","| epoch   1 |   510/  512 batches | loss  0.06\n","| epoch   1 |  Accuracy: 98.17%\n","\n","| epoch   2 |    51/  512 batches | loss  0.12\n","| epoch   2 |   102/  512 batches | loss  0.06\n","| epoch   2 |   153/  512 batches | loss  0.04\n","| epoch   2 |   204/  512 batches | loss  0.06\n","| epoch   2 |   255/  512 batches | loss  0.05\n","| epoch   2 |   306/  512 batches | loss  0.04\n","| epoch   2 |   357/  512 batches | loss  0.03\n","| epoch   2 |   408/  512 batches | loss  0.03\n","| epoch   2 |   459/  512 batches | loss  0.04\n","| epoch   2 |   510/  512 batches | loss  0.02\n","| epoch   2 |  Accuracy: 98.44%\n","\n","| epoch   3 |    51/  512 batches | loss  0.06\n","| epoch   3 |   102/  512 batches | loss  0.04\n","| epoch   3 |   153/  512 batches | loss  0.02\n","| epoch   3 |   204/  512 batches | loss  0.03\n","| epoch   3 |   255/  512 batches | loss  0.03\n","| epoch   3 |   306/  512 batches | loss  0.03\n","| epoch   3 |   357/  512 batches | loss  0.02\n","| epoch   3 |   408/  512 batches | loss  0.02\n","| epoch   3 |   459/  512 batches | loss  0.03\n","| epoch   3 |   510/  512 batches | loss  0.02\n","| epoch   3 |  Accuracy: 98.10%\n","\n","| epoch   4 |    51/  512 batches | loss  0.03\n","| epoch   4 |   102/  512 batches | loss  0.02\n","| epoch   4 |   153/  512 batches | loss  0.02\n","| epoch   4 |   204/  512 batches | loss  0.02\n","| epoch   4 |   255/  512 batches | loss  0.03\n","| epoch   4 |   306/  512 batches | loss  0.02\n","| epoch   4 |   357/  512 batches | loss  0.02\n","| epoch   4 |   408/  512 batches | loss  0.02\n","| epoch   4 |   459/  512 batches | loss  0.02\n","| epoch   4 |   510/  512 batches | loss  0.01\n","| epoch   4 |  Accuracy: 98.23%\n","\n","| epoch   5 |    51/  512 batches | loss  0.03\n","| epoch   5 |   102/  512 batches | loss  0.02\n","| epoch   5 |   153/  512 batches | loss  0.02\n","| epoch   5 |   204/  512 batches | loss  0.02\n","| epoch   5 |   255/  512 batches | loss  0.02\n","| epoch   5 |   306/  512 batches | loss  0.02\n","| epoch   5 |   357/  512 batches | loss  0.02\n","| epoch   5 |   408/  512 batches | loss  0.02\n","| epoch   5 |   459/  512 batches | loss  0.02\n","| epoch   5 |   510/  512 batches | loss  0.01\n","| epoch   5 |  Accuracy: 98.29%\n","\n","\n"," Final Accuracy: 98.02945301542778%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x79YkLMRiTYB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1600135022814,"user_tz":-540,"elapsed":274124,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"91416c17-f770-4971-e2a8-869c391bf62b"},"source":["path = './roberta-small-bulgarian-pos'\n","model.save_pretrained(path)\n","tokenizer.save_pretrained(path)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('./roberta-small-bulgarian-pos/vocab.json',\n"," './roberta-small-bulgarian-pos/merges.txt',\n"," './roberta-small-bulgarian-pos/special_tokens_map.json',\n"," './roberta-small-bulgarian-pos/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":8}]}]}